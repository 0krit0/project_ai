import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from datetime import datetime

# ===============================
# CONFIG
# ===============================
IMG_SIZE = 224
BATCH_SIZE = 16
EPOCHS = 5
FEEDBACK_DIR = "feedback_images"
MIN_IMAGES = 20
BASE_MODEL_PATH = "damage_model.h5"
CLASS_NAMES = ["low", "medium", "high"]
VALID_EXT = (".jpg", ".jpeg", ".png")

# ===============================
# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ feedback ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
# ===============================
def count_feedback_images():
    total = 0
    for level in CLASS_NAMES:
        path = os.path.join(FEEDBACK_DIR, level)
        if os.path.exists(path):
            total += len([
                f for f in os.listdir(path)
                if f.lower().endswith(VALID_EXT)
            ])
    return total

total_images = count_feedback_images()
print(f"üì∏ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ feedback ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_images}")

if total_images < MIN_IMAGES:
    print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ retrain")
    print(f"‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ {MIN_IMAGES} ‡∏£‡∏π‡∏õ")
    exit()

# ===============================
# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°
# ===============================
print("üîÑ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°...")
model = load_model(BASE_MODEL_PATH)

# ===============================
# Freeze feature extractor
# ===============================
for layer in model.layers[:-3]:
    layer.trainable = False

print("üîí Freeze layers ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (train ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ layer ‡∏ö‡∏ô)")

# ===============================
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å feedback_images
# ===============================
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=10,
    zoom_range=0.1,
    horizontal_flip=True
)

train_data = datagen.flow_from_directory(
    FEEDBACK_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="training"
)

val_data = datagen.flow_from_directory(
    FEEDBACK_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="validation"
)

# ===============================
# Compile ‡πÇ‡∏°‡πÄ‡∏î‡∏• (incremental learning)
# ===============================
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# ===============================
# Re-train
# ===============================
print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° Re-train ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å feedback...")
model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS,
    verbose=1
)

# ===============================
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà
# ===============================
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
new_model_name = f"damage_model_retrained_{timestamp}.h5"
model.save(new_model_name)

print("‚úÖ Re-train ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
print(f"üì¶ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô {new_model_name}")
print(f"üïí ‡πÄ‡∏ß‡∏•‡∏≤: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

